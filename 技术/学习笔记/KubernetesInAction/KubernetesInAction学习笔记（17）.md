---
name: KubernetesInAction学习笔记（17）
title: KubernetesInAction学习笔记（17）
tags: ["技术","学习笔记","KubernetesInAction"]
categories: 学习笔记
info: "第17章 开发应用的最佳实践"
time: 2021/3/19
desc: 'kubernetes in action, 资料下载, 学习笔记'
keywords: ['kubernetes in action', 'k8s学习', '学习笔记']
---

# KubernetesInAction学习笔记（17）

## 第17章 开发应用的最佳实践

本章将介绍一个常见的应用是如何跑在 K8S 上面的。

### 17.1 集中一切资源

一个实际跑在 K8S 上的应用程序会用到以下的 K8S 资源，下面是一个典型应用的 manifest：

![17-1.png](./images/17-1.png)

一个典型的应用 manifest 应该包含一个或多个 Deployment 和 StatefulSet 对象。这些对象中包含一个或者多个容器的 pod 模板，**而每个容器都有一个存活探针，并且为容器提供的服务（如果有的话）提供就绪探针**。提供服务的 pod 通过一个或者多个服务暴露自己，当需要从集群外访问这些服务的时候，**要么将这些服务配置为 LoadBalancer 或者 NodePort 类型的服务，要么通过 Ingress 资源来开放服务**。

pod 模板通常会引用两种类型的私密凭据（Secret）。一种是从私有镜像拉取镜像时使用的，另一种则是 pod 中运行的进程直接使用的。Secret 通常并不会是应用 manifest 的一部分，而是通常会通过分配给 ServiceAccount，然后再将 ServicAccount 分配给每个单独的 pod。

一个应用还包含一个或者多个 ConfigMap 对象，用于初始化环境变量，或者在 pod 中以 configMap 卷来挂载。有一些 pod 会使用额外的卷，如 emptyDir（用于在一个 pod 的多个容器中共享数据）或 gitRepo（用于在 pod 运行时自动拉取仓库），需要持久化存储的 pod 则需要 persistentVolumeClaim 卷，而被 persistentVolumeClaim 所引用的 StorageClass 则是由系统管理员事先创建的。

在某些情况下，一个应用还需要使用任务（Jobs）和定时任务（CronJobs）。而守护进程集（DaemonSet）一般不会做为应用部署的一部分，它们通常由系统管理员创建，在全部或者部分节点桑拿运行系统服务。

此外还有围绕 pod 的水平扩容器（HorizontalpodAutoscaler）可以由开发者包含在 manifest 中或者后续由运维团队添加到系统中。集群管理员还会在每个节点上创建 LimitRange 和 ResourceQuota 对象，以控制每个 pod 和所有的 pod 的计算资源使用情况。

在应用部署后，各种 K8S 控制器还会自动创建其他的对象，比如说 Endpoint controller 创建的 Endpoint 对象，Deployment controller 创建的 ReplicaSet 对象，以及由 ReplicaSet （或 RC，Job，CronJob，SS，DS）创建的实际的 pod 对象。

### 17.2 了解 pod 的生命周期

pod 是所有一切资源的中心，也是 K8S 中最重要的资源。从应用的角度来看 pod，它可以看作是一个轻量的虚拟机，但还是有很多显著的差异。

#### 17.2.1 应用必须预料到会被杀死或者重新调度

运行在虚拟机中的应用很少会被从一台机器迁移到另外一台机器。但是在 K8S 中，pod 会被频繁的调度，而其中的应用也就因此有可能随时会被杀死重启。这意味着开发者在开发的时候就要想到他们的应用应该可以支持被频繁迁移的场景。

##### 预料到本地 IP 和主机名会发生变化

应用开发者在开发一个跑在 K8S 场景下的应用时，要尽可能的不依赖应用所处的 IP 和主机名来进行开发。对于一些需要持久化的应用来说，K8S 可以使用 StatefulSet 来确保应用的主机名不会变化，但 IP 地址依旧无法保证。所以一个集群应用绝不应该依赖成员的 IP 地址来构建彼此的关系。

##### 预料到写入磁盘的数据会丢失/使用存储卷跨容器持久化数据

但个容器可能会因为各种原因被重启，当这种情况发生时，虽然 pod 还是一样，但是容器却是全新的了。Kubelet 不会将一个容器运行多次，而是会重新创建一个容器，所以应用不应该信赖在程序运行时容器文件系统中的所有文件。（除了挂载卷所在目录）

![17-2-3.png](./images/17-2-3.png)

但有时候使用存储卷来跨容器存储数据是把双刃剑，万一由于存储卷中的数据损坏而导致应用崩溃，就会使得容器无论重启多少次都陷入崩溃的状态（CrashLoopBackOff）。

#### 17.2.2 重新调度死亡或者部分死亡的 pod

如果一个 pod 陷入了无限循环的崩溃状态（CrashLoopBackOff），RS 或者类似的副本控制器是不会为环境自动移除这些 pod 的，只会由 kubelet 一直尝试重启下去，重启间隔也会不断变长，在这些间隔时，这些 pod 相当于“死亡”了，且节点上的可用副本数量也会因此 -1。

![17-4.png](./images/17-4.png)

为什么这些 pod 不会被自动移除呢？因为副本控制器并不关心 pod 是否处于死亡状态，它只关心 pod 的数量是否匹配期望的副本数量。

#### 17.2.3 以固定顺序启动 pod

有时应用之间会有相互依赖的关系，需要按照特定的顺序来进行启动。但在 K8S 上批量发布时，K8S 并没有内置的方法来先运行某些 pod，等其成功后再运行其他 pod。

##### 了解 pod 是如何启动的

K8S API 服务器确实是按照 YAML/JSON 文件中定义的对象的顺序来进行处理的，但是这只意味着它们在被写入到 etcd 的时候是有顺序的。无法确保 pod 会按照这个顺序启动。

但 K8S 允许开发者阻止一个一个容器的启动，**直到它的预置条件满足为止**。这个通过在 pod 中包含一个叫作 init 的容器来实现。

##### init 容器介绍

init 容器可以用来初始化 pod，这通常意味着向容器的存储卷中写入数据，然后将这个存储卷挂载到主容器中。

一个 pod 可以拥有任意数量的 init 容器。init 容器是顺序执行的，并且仅当最后一个 init 容器执行完毕才会去启动主容器。换句话说，init 容器也可以用来延迟 pod 的主容器的启动。

例如，直到满足某一个条件的时候，init 容器可以一直等待直到主容器所依赖的服务启动完成并且可以提供服务，然后 init 容器执行结束，然后主容器就可以启动了。

##### 将 init 容器加入 pod

init 容器可以在 pod spec 文件中像主容器那样定义。不过是通过字段`spec.initContainers`来定义的。

![code-17-2.png](./images/code-17-2.png)

当你部署这个 pod 的时候，只有 pod 的 init 容器会启动，这个 init 容器会向 fortune 服务发送响应，如果没有响应，init 将会一直重试。主容器会直到你部署的`fortune`服务和`fortune-server`pod 启动之后才会运行。

##### 处理 pod 内部依赖的最佳实践

虽然通过 init 容器可以延迟 pod 主容器的启动，但是更佳的情况是构建一个不需要它所依赖的服务都准备好后才能启动的应用，毕竟这些依赖的服务随时有可能下线。

应用需要保证自身能够应对它所依赖的服务没有准备好的情况，此外还可以为容器准备 Readiness 探针，用于在依赖缺失无法工作的时候能够通知 K8S，而且 K8S 也能知道这个应用没有准备好。

#### 17.2.4 增加生命周期钩子

pod 允许开发者定义两种类型的生命周期钩子：

- 启动后（Post-start）钩子
- 停止前（Pre-stop）钩子

这些生命周期的钩子和基于每个容器来指定的，和 init 容器不同的是，这些钩子并不会应用到 pod，而是在容器启动后和停止前执行的。

生命周期钩子与存活探针和就绪探针相似的是它们都可以：

- 在容器内部执行一个命令
- 向一个 URL 发送 HTTP GET 请求

##### 使用启动后容器生命周期钩子

postStart 钩子是在容器的主进程启动之后立即执行的（但并不会等待主进程执行完成，因为钩子并不知道主进程什么时候完成）。但在钩子执行完毕之前，容器和 pod 不会到达部署成功的状态，**如果钩子程序执行失败，容器会被杀死**。

![code-17-3.png](./images/code-17-3.png)

如果钩子程序失败了，会在 pod 的事件（可以通过`kubectl describe`命令查看）中看到一个 FaildPostStartHook 的告警信息。

##### 使用停止前容器生命周期钩子

当一个容器需要终止运行前，会立即执行停止前钩子 preStop。并且仅在执行完钩子子程序之后才会向容器进程发送 SIGTERM 信号（如果子进程没有终止运行，则会被杀死）。

这些钩子可以在容器终止前执行任意的操作（包括手动操作触发容器的关闭），并且不需要在应用内部实现这些操作。

![code-17-6.png](./images/code-17-6.png)

和 preStart 钩子执行失败会阻止容器启动不一样的是，preStop 钩子无论执行成功与否，容器都会被终止。如果停止前钩子执行失败了，就会在 pod 的事件中看到一个 FailedPreStopHook 告警。（但是因为可能 pod 不久后就会被删除，或许会无法及时看到这个告警）

##### 在应用没有收到 SIGTERM 信号时使用停止前钩子

在前面的章节介绍到，DockerFile 配置 ENTRYPOINT 或 CMD 有两种形式：

- exec 形式，直接运行应用的二进制文件，如：ENTRYPOINT ["/mybinary"]
- shell 形式，通过在容器内部起一个额外的 shell 来执行应用的二进制文件，如：ENTRYPOINT /mybinary

需要注意的是，如果是第二种形式，通过钩子向容器发送 SIGTERM 信号这种方式是无用的，因为这个信号会被这个额外的 shell 父进程给吞掉，而不会传送给应用。

所以，常用的合理做法是在 DockerFile 中使用 exec 的执行形式，如果一定要使用 shell 形式，那执行的脚本应该需要能够在接受不了到信号的时候将信号传递给应用。

##### 了解生命周期钩子是针对容器而不是 pod

pod 内部的生命周期钩子只会在容器被终止前调用，而这个过程在 pod 的生命周期中可能会发生多次，而不仅仅是在 pod 被关闭的时候。

#### 17.2.5 了解 pod 的关闭

本节探讨 pod 关闭的时候具体发生了什么，这对理解如何干净地关闭 pod 中运行的应用很重要。

最开始，pod 的关闭是通过 API 服务器删除 pod 的对象来触发的。接收到 HTTP DELETE 请求后，API 服务器还没有删除 pod 对象，而是给 pod 设置一个 deletionTimestamp 值。拥有 deletionTimestamp 的 pod 会自动开始停止流程。

Kubelet 在终止 pod 的时候，会首先尝试终止 pod 中的每个容器，Kubelet 会开启一个定时器让每个容器自行停止，并按照顺序执行以下事件：

1. 执行停止前钩子（如果配置了），等待它执行完毕
2. 向容器的主进程发送 SIGTERM 信号
3. 等待容器优雅地关闭或者等待定时器超时
4. 如果定时器超时，则使用 SIGKILL 信号强制终止进程

![17-5.png](./images/17-5.png)

##### 指定终止宽限期

通过 pod spec 中的`spec.terminationGracePeriod`字段可以设置删除容器等待定时器的值，单位为秒，默认为 30。

也可以在删除的时候加上`--grace-period`字段来覆盖。

```shell
$ kubectl delete pod mypod --grace-period=5
```

如果想要立刻删除 pod 资源而不进行等待，可以将该值设为 0，然后强制执行。

```shell
$ kubectl delete pod mypod --grace-period=0 --force
```

使用这个命令来删除 pod 时需要非常小心，强制删除 pod 会导致像 deployment、rs、ss 这些控制器不会等待被删的 pod 里面的容器完成关闭就创建了一个替代的 pod。换句话说，相同的 pod 的两个实例可能会在同一时间运行，对于一些有状态要求的应用来说，这可能会导致应用集群工作异常。

![17-8.png](./images/17-8.png)

### 17.3 确保所有的客户端请求都得到了处理

为了避免客户端把请求发送到没有准备好的 pod 上导致请求丢失，开发者应该做好以下几点：

- 只有当应用准备好处理请求的时候才让 pod 的就绪探针返回成功，最佳的方法就是添加一个指向应用 URL 的 HTTP GET 请求的就绪探针

- 在 pod 关闭时避免客户端链接断开（原文在这部分介绍了很久...总结一下就是因为 K8S 是多组件并行执行的，没有一个完美的办法可以彻底避免这个情况），包括如下步骤：

  - 等待几秒钟，停止接收新的连接
  - 关闭所有没有请求过来的长连接
  - 等待所有的请求都完成
  - 然后完全关闭应用

  ![17-9.png](./images/17-9.png)

  当然，如果你不想这么麻烦，可以简单的加一个 preStop 钩子，这样起码可以确保所有已经进来了的请求能够得到处理。（但是后续由于 EndPoint 没有关闭而误入的请求就没有办法了）

  ![code-17-7.png](./images/code-17-7.png)

### 17.5 开发和测试的最佳实践

#### 17.5.2 在开发过程中使用 Minikube

如果你正在使用 Minikube 进行开发，可以使用`minikube mount`命令将本地的文件系统挂载到 Minikube VM 中。然后通过一个 hostPath 卷挂载到容器中。 

如果你在本地的机器已经构建好了镜像，可以使用下面的命令将镜像直接复制到 Mnikube VM 中。

```shell
docker save <image> | (eval $(minikube docker-env) && docker load)
```

和之前一样这个镜像就可以在 pod 中立即使用了，但要注意要把 pod manifest 文件的 imagePullPolicy 选项设置为 Never，否则这会导致从外部镜像中心拉取而不是使用本地的镜像。

#### 17.5.3 发布版本和自动部署资源清单

通过版本控制工具，比如说 Git、SVN 等等工具，将资源的 manifest 做版本控制，这样可以方便 K8S 对部署的资源进行回滚。因为 K8S 采用的是指令式模型，所以只要使用`kubectl apply`这类命令就可以将更改反映到部署的资源中，K8S 会自行采取相关的必要措施来将集群的状态切换到你期望的样子。

#### 17.5.4 使用 Ksonnet 作为编写 YAML/JSON manifest 文件的额外选择

Ksonnet 是基于 Jsonnet 开发的一个库，可以用来定义一些参数化的 JSON 片段，这样就不需要在多个地方重复编写相同的 JSON 代码了，有点类似于编程语言中调用的工厂函数或方法。

![code-17-10.png](./images/code-17-10.png)

```shell
$ jsonnet kubia.ksonnet
```

使用上面的命令就可以将上面定义的代码转换为一个完整的 JSON 格式的 Deployment 配置文件了。

#### 17.5.5 利用持续集成和持续交付

将 K8S 和 GitLab/GitHub 的 CI/CD 工作流结合起来，就可以完成一个自动化的工作流，用于构建应用的二进制文件、容器镜像以及资源配置，然后部署到一个或者多个 K8S 集群中。

网络上有很多讨论这方面的资源，感兴趣的话可以关注[Fabric](http://fabric8.io)这个项目，这是一个 K8S 的集成开发平台，包括著名的自动化集成系统 Jenkins 以及各种完整的 CI/CD 工作流的工具。

